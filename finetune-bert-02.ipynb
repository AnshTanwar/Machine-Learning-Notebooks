{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8600001,"sourceType":"datasetVersion","datasetId":5092991}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-04T11:53:09.404133Z","iopub.execute_input":"2024-06-04T11:53:09.404482Z","iopub.status.idle":"2024-06-04T11:53:10.383178Z","shell.execute_reply.started":"2024-06-04T11:53:09.404453Z","shell.execute_reply":"2024-06-04T11:53:10.382174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data import and cleaning up the data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/crypto-regulations-yirifi/mappingtoBERT_6.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:10.384788Z","iopub.execute_input":"2024-06-04T11:53:10.385263Z","iopub.status.idle":"2024-06-04T11:53:10.465322Z","shell.execute_reply.started":"2024-06-04T11:53:10.385238Z","shell.execute_reply":"2024-06-04T11:53:10.464557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:10.466395Z","iopub.execute_input":"2024-06-04T11:53:10.466669Z","iopub.status.idle":"2024-06-04T11:53:10.475514Z","shell.execute_reply.started":"2024-06-04T11:53:10.466646Z","shell.execute_reply":"2024-06-04T11:53:10.474609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:10.478298Z","iopub.execute_input":"2024-06-04T11:53:10.478936Z","iopub.status.idle":"2024-06-04T11:53:10.496305Z","shell.execute_reply.started":"2024-06-04T11:53:10.478911Z","shell.execute_reply":"2024-06-04T11:53:10.495503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n# Function to check for URLs\ndef contains_url(text):\n    text = str(text)\n    return bool(re.search(r'http\\S+|www\\S+|https\\S+', text))\n\n# Function to check for user references (@user)\ndef contains_user_reference(text):\n    text = str(text)\n    return bool(re.search(r'\\@\\w+', text))\n\n# Function to check for hashtags\ndef contains_hashtag(text):\n    text = str(text)\n    return bool(re.search(r'\\#\\w+', text))\n\n# Function to check for non-alphanumeric characters\ndef contains_non_alphanumeric(text):\n    text = str(text)\n    return bool(re.search(r'[^a-zA-Z0-9\\s]', text))\n\n# Apply the functions to the DataFrame\ndf['contains_url'] = df['Content'].apply(contains_url)\ndf['contains_user_reference'] = df['Content'].apply(contains_user_reference)\ndf['contains_hashtag'] = df['Content'].apply(contains_hashtag)\ndf['contains_non_alphanumeric'] = df['Content'].apply(contains_non_alphanumeric)\n\n# Check rows that match each condition\nurl_count = df['contains_url'].sum()\nuser_reference_count = df['contains_user_reference'].sum()\nhashtag_count = df['contains_hashtag'].sum()\nnon_alphanumeric_count = df['contains_non_alphanumeric'].sum()\n\n# Print results\nprint(f\"Number of rows with URLs: {url_count}\")\nprint(f\"Number of rows with user references: {user_reference_count}\")\nprint(f\"Number of rows with hashtags: {hashtag_count}\")\nprint(f\"Number of rows with non-alphanumeric characters: {non_alphanumeric_count}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:10.497297Z","iopub.execute_input":"2024-06-04T11:53:10.497545Z","iopub.status.idle":"2024-06-04T11:53:10.592746Z","shell.execute_reply.started":"2024-06-04T11:53:10.497523Z","shell.execute_reply":"2024-06-04T11:53:10.591851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:10.593977Z","iopub.execute_input":"2024-06-04T11:53:10.594259Z","iopub.status.idle":"2024-06-04T11:53:10.606973Z","shell.execute_reply.started":"2024-06-04T11:53:10.594235Z","shell.execute_reply":"2024-06-04T11:53:10.606027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[[\"Content\",\"bert_concepts\"]]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:10.608341Z","iopub.execute_input":"2024-06-04T11:53:10.608637Z","iopub.status.idle":"2024-06-04T11:53:10.617516Z","shell.execute_reply.started":"2024-06-04T11:53:10.608612Z","shell.execute_reply":"2024-06-04T11:53:10.616645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\n\ndef preprocess_text(text):\n    text = str(text)    \n    text = re.sub(r'<[^>]+>', '', text) # Remove HTML tags\n    text = text.lower()\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)# Remove URLs\n    text = re.sub(r'\\@\\w+|\\#','', text) # Remove user @ references and hashtags\n    text = text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation    \n    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text) # Remove non-alphanumeric character    \n    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace(only single white space is left)\n    \n    return text\n\ndf['Content'] = df['Content'].apply(preprocess_text) # Applying the preprocess_text function\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:10.618592Z","iopub.execute_input":"2024-06-04T11:53:10.618914Z","iopub.status.idle":"2024-06-04T11:53:10.981764Z","shell.execute_reply.started":"2024-06-04T11:53:10.618885Z","shell.execute_reply":"2024-06-04T11:53:10.980753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:10.983254Z","iopub.execute_input":"2024-06-04T11:53:10.983637Z","iopub.status.idle":"2024-06-04T11:53:10.994086Z","shell.execute_reply.started":"2024-06-04T11:53:10.983608Z","shell.execute_reply":"2024-06-04T11:53:10.992648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:10.999288Z","iopub.execute_input":"2024-06-04T11:53:10.999605Z","iopub.status.idle":"2024-06-04T11:53:11.006516Z","shell.execute_reply.started":"2024-06-04T11:53:10.999579Z","shell.execute_reply":"2024-06-04T11:53:11.005529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_count = df['bert_concepts'].isnull().sum()\nprint(\"Number of rows with NaN in bert_concepts:\", missing_values_count)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:11.007710Z","iopub.execute_input":"2024-06-04T11:53:11.008036Z","iopub.status.idle":"2024-06-04T11:53:11.014936Z","shell.execute_reply.started":"2024-06-04T11:53:11.008013Z","shell.execute_reply":"2024-06-04T11:53:11.014006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove rows with no bert_concepts","metadata":{}},{"cell_type":"code","source":"df = df.dropna(subset=['bert_concepts'])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:11.016129Z","iopub.execute_input":"2024-06-04T11:53:11.016461Z","iopub.status.idle":"2024-06-04T11:53:11.027543Z","shell.execute_reply.started":"2024-06-04T11:53:11.016432Z","shell.execute_reply":"2024-06-04T11:53:11.026516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:11.028734Z","iopub.execute_input":"2024-06-04T11:53:11.029087Z","iopub.status.idle":"2024-06-04T11:53:11.037252Z","shell.execute_reply.started":"2024-06-04T11:53:11.029060Z","shell.execute_reply":"2024-06-04T11:53:11.036305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting to Bert Data Format","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset, DatasetDict","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:11.038463Z","iopub.execute_input":"2024-06-04T11:53:11.038685Z","iopub.status.idle":"2024-06-04T11:53:13.218897Z","shell.execute_reply.started":"2024-06-04T11:53:11.038666Z","shell.execute_reply":"2024-06-04T11:53:13.218142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:13.219923Z","iopub.execute_input":"2024-06-04T11:53:13.220344Z","iopub.status.idle":"2024-06-04T11:53:13.226142Z","shell.execute_reply.started":"2024-06-04T11:53:13.220319Z","shell.execute_reply":"2024-06-04T11:53:13.225284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf['bert_concepts'] = df['bert_concepts'].apply(lambda x: x.split(', ')) # make list of words\nall_concepts = set(concept for row in df['bert_concepts'] for concept in row) # Create a list of all unique concepts\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:13.227308Z","iopub.execute_input":"2024-06-04T11:53:13.227635Z","iopub.status.idle":"2024-06-04T11:53:13.243202Z","shell.execute_reply.started":"2024-06-04T11:53:13.227604Z","shell.execute_reply":"2024-06-04T11:53:13.242312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_concepts","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:13.244323Z","iopub.execute_input":"2024-06-04T11:53:13.244604Z","iopub.status.idle":"2024-06-04T11:53:13.255437Z","shell.execute_reply.started":"2024-06-04T11:53:13.244573Z","shell.execute_reply":"2024-06-04T11:53:13.254617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One-hot encode each concept for each row\none_hot_encoded_rows = []\nfor index, row in df.iterrows():\n    one_hot_row = {'Content': row['Content']}\n    for concept in all_concepts:\n        one_hot_row[concept] = True if concept in row['bert_concepts'] else False\n    one_hot_encoded_rows.append(one_hot_row)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:13.256459Z","iopub.execute_input":"2024-06-04T11:53:13.256716Z","iopub.status.idle":"2024-06-04T11:53:14.906366Z","shell.execute_reply.started":"2024-06-04T11:53:13.256695Z","shell.execute_reply":"2024-06-04T11:53:14.905368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"one_hot_encoded_rows[:2]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:14.907636Z","iopub.execute_input":"2024-06-04T11:53:14.907946Z","iopub.status.idle":"2024-06-04T11:53:14.917338Z","shell.execute_reply.started":"2024-06-04T11:53:14.907922Z","shell.execute_reply":"2024-06-04T11:53:14.916396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(one_hot_encoded_rows)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:14.918521Z","iopub.execute_input":"2024-06-04T11:53:14.918786Z","iopub.status.idle":"2024-06-04T11:53:14.985939Z","shell.execute_reply.started":"2024-06-04T11:53:14.918761Z","shell.execute_reply":"2024-06-04T11:53:14.985195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:14.987190Z","iopub.execute_input":"2024-06-04T11:53:14.987733Z","iopub.status.idle":"2024-06-04T11:53:15.009490Z","shell.execute_reply.started":"2024-06-04T11:53:14.987702Z","shell.execute_reply":"2024-06-04T11:53:15.008668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:15.010679Z","iopub.execute_input":"2024-06-04T11:53:15.010990Z","iopub.status.idle":"2024-06-04T11:53:15.017505Z","shell.execute_reply.started":"2024-06-04T11:53:15.010966Z","shell.execute_reply":"2024-06-04T11:53:15.016698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting DataFrame into train, test, and validation sets\ntrain_df, test_valid_df = train_test_split(df, test_size=0.3, random_state=42)\ntest_df, validation_df = train_test_split(test_valid_df, test_size=0.33, random_state=42)\n\n# Convert DataFrames to Hugging Face Datasets\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)\nvalidation_dataset = Dataset.from_pandas(validation_df)\n\n# Create DatasetDict\ndataset = DatasetDict({\n    \"train\": train_dataset,\n    \"test\": test_dataset,\n    \"validation\": validation_dataset\n})\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:15.018577Z","iopub.execute_input":"2024-06-04T11:53:15.018902Z","iopub.status.idle":"2024-06-04T11:53:15.216531Z","shell.execute_reply.started":"2024-06-04T11:53:15.018873Z","shell.execute_reply":"2024-06-04T11:53:15.215601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:15.217694Z","iopub.execute_input":"2024-06-04T11:53:15.217982Z","iopub.status.idle":"2024-06-04T11:53:15.223564Z","shell.execute_reply.started":"2024-06-04T11:53:15.217959Z","shell.execute_reply":"2024-06-04T11:53:15.222608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[i for i in dataset['train']][:2]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:15.224836Z","iopub.execute_input":"2024-06-04T11:53:15.225117Z","iopub.status.idle":"2024-06-04T11:53:17.459716Z","shell.execute_reply.started":"2024-06-04T11:53:15.225095Z","shell.execute_reply":"2024-06-04T11:53:17.458865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Ready Now Training","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers datasets","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:17.461116Z","iopub.execute_input":"2024-06-04T11:53:17.461748Z","iopub.status.idle":"2024-06-04T11:53:20.298865Z","shell.execute_reply.started":"2024-06-04T11:53:17.461713Z","shell.execute_reply":"2024-06-04T11:53:20.297884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size, num_labels), indicating the unnormalized scores for a number of labels for every example in the batch.","metadata":{}},{"cell_type":"markdown","source":"### List containing all the labels","metadata":{}},{"cell_type":"code","source":"labels = [label for label in dataset['train'].features.keys() if label not in ['Content','__index_level_0__']]\n#Create 2 dictionaries that map labels to integers and back.\nid2label = {idx:label for idx, label in enumerate(labels)}\nlabel2id = {label:idx for idx, label in enumerate(labels)}\nlabels","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:20.300383Z","iopub.execute_input":"2024-06-04T11:53:20.300711Z","iopub.status.idle":"2024-06-04T11:53:20.311699Z","shell.execute_reply.started":"2024-06-04T11:53:20.300678Z","shell.execute_reply":"2024-06-04T11:53:20.310683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2label","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:20.319108Z","iopub.execute_input":"2024-06-04T11:53:20.319440Z","iopub.status.idle":"2024-06-04T11:53:20.328165Z","shell.execute_reply.started":"2024-06-04T11:53:20.319416Z","shell.execute_reply":"2024-06-04T11:53:20.327257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"markdown","source":"### As models like BERT don't expect text as direct input, but rather input_ids, etc., we tokenize the text using the tokenizer. We will use AutoTokenizer API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n\n### What's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' BCEWithLogitsLoss (which the model will use) will complain","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport numpy as np\n\ntokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n\ndef preprocess_data(examples, max_length=128):\n  # take a batch of texts\n  text = examples['Content']\n  batch_size = len(text)\n  # encode them\n  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=max_length)\n  # add labels\n  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n  # create numpy array of shape (batch_size, num_labels)\n  labels_matrix = np.zeros((len(text), len(labels)))\n  # fill numpy array\n  for idx, label in enumerate(labels):\n    labels_matrix[:, idx] = labels_batch[label]\n\n  encoding[\"labels\"] = labels_matrix.tolist()\n  \n  return encoding","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:20.330453Z","iopub.execute_input":"2024-06-04T11:53:20.330724Z","iopub.status.idle":"2024-06-04T11:53:26.959469Z","shell.execute_reply.started":"2024-06-04T11:53:20.330701Z","shell.execute_reply":"2024-06-04T11:53:26.958524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:26.960558Z","iopub.execute_input":"2024-06-04T11:53:26.961034Z","iopub.status.idle":"2024-06-04T11:53:28.317686Z","shell.execute_reply.started":"2024-06-04T11:53:26.961007Z","shell.execute_reply":"2024-06-04T11:53:28.316815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:28.319035Z","iopub.execute_input":"2024-06-04T11:53:28.319516Z","iopub.status.idle":"2024-06-04T11:53:28.325108Z","shell.execute_reply.started":"2024-06-04T11:53:28.319482Z","shell.execute_reply":"2024-06-04T11:53:28.324261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_dataset['train']","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:28.326429Z","iopub.execute_input":"2024-06-04T11:53:28.326985Z","iopub.status.idle":"2024-06-04T11:53:28.335716Z","shell.execute_reply.started":"2024-06-04T11:53:28.326954Z","shell.execute_reply":"2024-06-04T11:53:28.334780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = encoded_dataset['train'][0]\ntokenizer.decode(example['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:28.336956Z","iopub.execute_input":"2024-06-04T11:53:28.337276Z","iopub.status.idle":"2024-06-04T11:53:38.814611Z","shell.execute_reply.started":"2024-06-04T11:53:28.337238Z","shell.execute_reply":"2024-06-04T11:53:38.813563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#example['labels']","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:38.815836Z","iopub.execute_input":"2024-06-04T11:53:38.816462Z","iopub.status.idle":"2024-06-04T11:53:38.820493Z","shell.execute_reply.started":"2024-06-04T11:53:38.816435Z","shell.execute_reply":"2024-06-04T11:53:38.819495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use id to label dictionary\n[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]\nencoded_dataset.set_format(\"torch\") ","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:38.821572Z","iopub.execute_input":"2024-06-04T11:53:38.821856Z","iopub.status.idle":"2024-06-04T11:53:38.831968Z","shell.execute_reply.started":"2024-06-04T11:53:38.821833Z","shell.execute_reply":"2024-06-04T11:53:38.831084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n\n### We set the problem_type to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely BCEWithLogitsLoss). We also make sure the output layer has len(labels) output neurons, and we set the id2label and label2id mappings","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\", \n                                                           problem_type=\"multi_label_classification\", \n                                                           num_labels=len(labels),\n                                                           id2label=id2label,\n                                                           label2id=label2id,\n                                                          ignore_mismatched_sizes=True )","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:38.833063Z","iopub.execute_input":"2024-06-04T11:53:38.833309Z","iopub.status.idle":"2024-06-04T11:53:54.406901Z","shell.execute_reply.started":"2024-06-04T11:53:38.833287Z","shell.execute_reply":"2024-06-04T11:53:54.405930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\nmetric_name = \"f1\"","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:54.408252Z","iopub.execute_input":"2024-06-04T11:53:54.408835Z","iopub.status.idle":"2024-06-04T11:53:54.413338Z","shell.execute_reply.started":"2024-06-04T11:53:54.408784Z","shell.execute_reply":"2024-06-04T11:53:54.412453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nargs = TrainingArguments(\n    f\"bert-finetuned-sem_eval-english\",\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=metric_name\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:23.493646Z","iopub.execute_input":"2024-06-04T11:56:23.494460Z","iopub.status.idle":"2024-06-04T11:56:23.521872Z","shell.execute_reply.started":"2024-06-04T11:56:23.494426Z","shell.execute_reply":"2024-06-04T11:56:23.520952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we need to define a compute_metrics function, that returns a dictionary with the desired metric values.\n\nsource: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nfrom transformers import EvalPrediction\nimport torch\n    \n\ndef multi_label_metrics(predictions, labels, threshold=0.5):\n    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(torch.Tensor(predictions))\n    # next, use threshold to turn them into integer predictions\n    y_pred = np.zeros(probs.shape)\n    y_pred[np.where(probs >= threshold)] = 1\n    # finally, compute metrics\n    y_true = labels\n    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n    accuracy = accuracy_score(y_true, y_pred)\n    # return as dictionary\n    metrics = {'f1': f1_micro_average,\n               'roc_auc': roc_auc,\n               'accuracy': accuracy}\n    return metrics\n\ndef compute_metrics(p: EvalPrediction):\n    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n    result = multi_label_metrics(predictions=preds,labels=p.label_ids)\n    return result\n  \n   \n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:26.016720Z","iopub.execute_input":"2024-06-04T11:56:26.017411Z","iopub.status.idle":"2024-06-04T11:56:26.025432Z","shell.execute_reply.started":"2024-06-04T11:56:26.017379Z","shell.execute_reply":"2024-06-04T11:56:26.024509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_dataset['train'][0]['labels'].type()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:26.055268Z","iopub.execute_input":"2024-06-04T11:56:26.055750Z","iopub.status.idle":"2024-06-04T11:56:26.063000Z","shell.execute_reply.started":"2024-06-04T11:56:26.055724Z","shell.execute_reply":"2024-06-04T11:56:26.062123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_dataset['train']['input_ids'][0]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:26.093458Z","iopub.execute_input":"2024-06-04T11:56:26.094030Z","iopub.status.idle":"2024-06-04T11:56:26.109898Z","shell.execute_reply.started":"2024-06-04T11:56:26.094005Z","shell.execute_reply":"2024-06-04T11:56:26.108912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #forward pass\n# #, attention_mask=attention_mask\n# outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n# outputs","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:26.135688Z","iopub.execute_input":"2024-06-04T11:56:26.135961Z","iopub.status.idle":"2024-06-04T11:56:26.139595Z","shell.execute_reply.started":"2024-06-04T11:56:26.135938Z","shell.execute_reply":"2024-06-04T11:56:26.138725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, Trainer","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:26.166174Z","iopub.execute_input":"2024-06-04T11:56:26.166421Z","iopub.status.idle":"2024-06-04T11:56:26.170425Z","shell.execute_reply.started":"2024-06-04T11:56:26.166399Z","shell.execute_reply":"2024-06-04T11:56:26.169503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:26.188488Z","iopub.execute_input":"2024-06-04T11:56:26.188729Z","iopub.status.idle":"2024-06-04T11:56:26.494608Z","shell.execute_reply.started":"2024-06-04T11:56:26.188708Z","shell.execute_reply":"2024-06-04T11:56:26.493847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['WANDB_API_KEY'] =\"313a57558bcaee784e68d1654f7915a0b463a341\"","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:26.496083Z","iopub.execute_input":"2024-06-04T11:56:26.496385Z","iopub.status.idle":"2024-06-04T11:56:26.500575Z","shell.execute_reply.started":"2024-06-04T11:56:26.496360Z","shell.execute_reply":"2024-06-04T11:56:26.499606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:26.501728Z","iopub.execute_input":"2024-06-04T11:56:26.502043Z","iopub.status.idle":"2024-06-04T11:56:27.293591Z","shell.execute_reply.started":"2024-06-04T11:56:26.502020Z","shell.execute_reply":"2024-06-04T11:56:27.292635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:56:27.295610Z","iopub.execute_input":"2024-06-04T11:56:27.295911Z","iopub.status.idle":"2024-06-04T12:07:49.563829Z","shell.execute_reply.started":"2024-06-04T11:56:27.295885Z","shell.execute_reply":"2024-06-04T12:07:49.563028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:07:49.565087Z","iopub.execute_input":"2024-06-04T12:07:49.565449Z","iopub.status.idle":"2024-06-04T12:07:51.924321Z","shell.execute_reply.started":"2024-06-04T12:07:49.565415Z","shell.execute_reply":"2024-06-04T12:07:51.923227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\nadd Codeadd Markdown\nThe logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the batch_size equals 1.\n\nThe logits is a tensor that contains the (unnormalized) scores for every individual label.\n\nThe logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the batch_size equals 1.\n\nThe logits is a tensor that contains the (unnormalized) scores for every individual label.","metadata":{}},{"cell_type":"code","source":"def get_answer(text):\n    \n    encoding = tokenizer(text, return_tensors=\"pt\")\n    encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n    outputs = trainer.model(**encoding)\n    logits = outputs.logits\n    print(logits.shape)\n    \n    # apply sigmoid + threshold\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(logits.squeeze().cpu())\n    print(probs)\n    predictions = np.zeros(probs.shape)\n    predictions[np.where(probs >= 0.5)] = 1\n    print(predictions)\n    predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n    print()\n    return predicted_labels\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:16:44.742572Z","iopub.execute_input":"2024-06-04T12:16:44.743258Z","iopub.status.idle":"2024-06-04T12:16:44.752022Z","shell.execute_reply.started":"2024-06-04T12:16:44.743223Z","shell.execute_reply":"2024-06-04T12:16:44.750964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"The new licensing regime for centralised virtual asset trading platforms under the Anti-MoneyLaundering and Counter-Terrorist Financing Ordinance (Cap. 615) (AMLO) will come intoeffect on 1 June 2023. Under the new regime, centralised virtual asset trading platformsoperating in Hong Kong will need to apply to the Securities and Futures Commission (SFC)for a licence under the Securities and Futures Ordinance (Cap 571) (SFO) and/or the AMLO(Dual Licence Arrangement)\"\nget_answer(text)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:16:45.300567Z","iopub.execute_input":"2024-06-04T12:16:45.301464Z","iopub.status.idle":"2024-06-04T12:16:45.328377Z","shell.execute_reply.started":"2024-06-04T12:16:45.301425Z","shell.execute_reply":"2024-06-04T12:16:45.327340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Probability","metadata":{}},{"cell_type":"code","source":"# outputs = trainer.model(**encoding)\n# logits = outputs.logits\n# logits.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:14:22.316699Z","iopub.execute_input":"2024-06-04T12:14:22.317499Z","iopub.status.idle":"2024-06-04T12:14:22.322749Z","shell.execute_reply.started":"2024-06-04T12:14:22.317465Z","shell.execute_reply":"2024-06-04T12:14:22.321520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the batch_size equals 1.\n\nThe logits is a tensor that contains the (unnormalized) scores for every individual label\n\nTo turn them into actual predicted labels, we first apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1, that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n\nNext, we use a threshold (typically, 0.5) to turn every probability into either a 1 (which means, we predict the label for the given example) or a 0 (which means, we don't predict the label for the given example)","metadata":{}},{"cell_type":"code","source":"# # apply sigmoid + threshold\n# sigmoid = torch.nn.Sigmoid()\n# probs = sigmoid(logits.squeeze().cpu())\n# predictions = np.zeros(probs.shape)\n# predictions[np.where(probs >= 0.5)] = 1\n# # turn predicted id's into actual label names\n# predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n# print(predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:14:23.127781Z","iopub.execute_input":"2024-06-04T12:14:23.128180Z","iopub.status.idle":"2024-06-04T12:14:23.133964Z","shell.execute_reply.started":"2024-06-04T12:14:23.128152Z","shell.execute_reply":"2024-06-04T12:14:23.133004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}